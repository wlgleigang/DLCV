{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 实战项目：图像标注\n",
    "\n",
    "---\n",
    "\n",
    "在该 notebook 中，你要学习的是如何从 [COCO 数据集](http://cocodataset.org/#home) 中对数据进行加载和预处理。此外，你还要设计一个CNN-RNN模型，使其自动生成图像标注。\n",
    "但是，**models.py**文件，从而实现你自己的CNN编码器和RNN解码器。我们将对你的**models.py** 文件进行评分。\n",
    "\n",
    "点击以下链接，即可进入此 notebook：\n",
    "- [Step 1](#step1): 了解数据加载器\n",
    "- [Step 2](#step2): 使用数据加载器获取批次\n",
    "- [Step 3](#step3): 使用CNN编码器进行实验\n",
    "- [Step 4](#step4): 实现RNN解码器\n",
    "\n",
    "<a id='step1'></a>\n",
    "## Step 1: 了解数据加载器\n",
    "\n",
    "我们已经编写了一个 [ 数据加载器](http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader) ，你可以使用它来批量加载COCO数据集。\n",
    "\n",
    "在下面的代码单元格中，你可以使用 **data_loader.py** 中的`get_loader` 函数对数据加载器初始化。\n",
    "\n",
    "> 在这个项目中，请不要修改 **data_loader.py** 文件，务必保留其原样。\n",
    "\n",
    " `get_loader` 函数将 **data_loader.py** 中可以用来探索的许多参数作为输入。现在，花一些时间在新窗口中打开 **data_loader.py**，并研究这些参数。大多数参数必须保留其默认值，只有以下参数的值允许被修改：\n",
    "1. **`transform`** -  [图像转换 ](http://pytorch.org/docs/master/torchvision/transforms.html) 具体规定了应该如何对图像进行预处理，并将它们转换为PyTorch张量，然后再将它们用作CNN编码器的输入。在这里，我们建议你保留`transform_train`中提供的转换方法。之后，你可以选择自己的图像转换方法，对COCO图像进行预处理。\n",
    "2. **`mode`** - `'train'`（用于批量加载训练数据）或 `'test'`（用于测试数据），二者中的一个。我们将分别说明数据加载器处于训练模式或测试模式的情况。参照该 notebook 中的说明进行操作时，请设置`mode='train'`.`'train'`，这样可以使数据加载器处于训练模式。\n",
    "3. **`batch_size`** - 它是用于确定批次的大小。训练你的模型时，它是指图像标注对的数量，用于在每个训练步骤中修改模型权重。\n",
    "4. **`vocab_threshold`** - 它是指在将单词用作词汇表的一部分之前，单词必须出现在训练图像标注中的总次数。在训练图像标注中出现少于`vocab_threshold` 的单词将被认为是未知单词。\n",
    "5. **`vocab_from_file`** -  它是指一个布尔运算（Boolean），用于决定是否从文件中加载词汇表。\n",
    "\n",
    "接下来，我们将更详细地描述`vocab_threshold` 和 `vocab_from_file`参数。现在，运行下面的代码单元格。要有耐心哦，可能需要几分钟才能运行！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "loading annotations into memory...\n",
      "Done (t=0.83s)\n",
      "creating index...\n",
      "index created!\n",
      "[0/414113] Tokenizing captions...\n",
      "[100000/414113] Tokenizing captions...\n",
      "[200000/414113] Tokenizing captions...\n",
      "[300000/414113] Tokenizing captions...\n",
      "[400000/414113] Tokenizing captions...\n",
      "loading annotations into memory...\n",
      "Done (t=0.82s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 623/414113 [00:00<01:06, 6227.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414113/414113 [01:08<00:00, 6019.74it/s]\n"
     ]
    }
   ],
   "source": [
    "#vocab_threshold   确定为词汇表内的词最少出现的次数,否则unknown words\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from data_loader import get_loader\n",
    "from torchvision import transforms\n",
    "\n",
    "# 定义转化器预处理训练集图片\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # 把较小的边缘缩小的256\n",
    "    transforms.RandomCrop(224),                      # 随机剪裁224x224\n",
    "    transforms.RandomHorizontalFlip(),               # 有0.5的概率水平翻转\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # 标准化图像\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "# 设定最小的次数阈值\n",
    "vocab_threshold = 5\n",
    "# 批量大小\n",
    "batch_size = 10\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行上面的代码单元格时，数据加载器会存储在变量`data_loader`中。\n",
    "\n",
    "你可以将相应的数据集以`data_loader.dataset` 的方式访问。 此数据集是**data_loader.py**中`CoCoDataset`类的一个实例。 如果你对数据加载器和数据集感到陌生，我们建议你查看 [ 此 PyTorch 教程 ](http://pytorch.org/tutorials/beginner/data_loading_tutorial.html)。\n",
    "\n",
    "### 了解 `__getitem__` 方法\n",
    "\n",
    " `CoCoDataset`类中的`__getitem__`方法用于确定图像标注对在合并到批处理之前应如何进行预处理。 PyTorch中的所有`Dataset` 类都是如此。如果你此感到陌生，请查看 [上面链接中的教程 ](http://pytorch.org/tutorials/beginner/data_loading_tutorial.html)。\n",
    "\n",
    "当数据加载器处于训练模式时，该方法将首先获得训练图像的文件名（`path`）及其对应的标注（`caption`）。\n",
    "\n",
    "#### 图像预处理 \n",
    "\n",
    "图像预处理相对比较简单（来自`CoCoDataset`类中的`__getitem__`方法）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_caption = 'A person doing a trick on a rail while riding a skateboard.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的代码,先将字符串小写,然后通过[`nltk.tokenize.word_tokenize`](http://www.nltk.org/) 函数,分解为单词的列表."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'person', 'doing', 'a', 'trick', 'on', 'a', 'rail', 'while', 'riding', 'a', 'skateboard', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "sample_tokens = nltk.tokenize.word_tokenize(str(sample_caption).lower())\n",
    "print(sample_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下面代码,定义一个空的列表,然后添加一个代表着开始的整数,表示开始的字符串(`\"<start>\"`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special start word: <start>\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "sample_caption = []\n",
    "start_word = data_loader.dataset.vocab.start_word\n",
    "print('Special start word:', start_word)\n",
    "sample_caption.append(data_loader.dataset.vocab(start_word))\n",
    "print(sample_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面代码,为每一个单词赋予整数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 98, 754, 3, 396, 39, 3, 1009, 207, 139, 3, 753, 18]\n"
     ]
    }
   ],
   "source": [
    "sample_caption.extend([data_loader.dataset.vocab(token) for token in sample_tokens])\n",
    "print(sample_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下面代码,添加一个代表着结束的整数,表示结束的字符串(`\"<start>\"`) 所以整数0代表句子开始,1表示代表句子结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special end word: <end>\n",
      "[0, 3, 98, 754, 3, 396, 39, 3, 1009, 207, 139, 3, 753, 18, 1]\n"
     ]
    }
   ],
   "source": [
    "end_word = data_loader.dataset.vocab.end_word\n",
    "print('Special end word:', end_word)\n",
    "sample_caption.append(data_loader.dataset.vocab(end_word))\n",
    "print(sample_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,     3,    98,   754,     3,   396,    39,     3,  1009,\n",
      "          207,   139,     3,   753,    18,     1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sample_caption = torch.LongTensor(sample_caption)\n",
    "print(sample_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[<start>, 'a', 'person', 'doing', 'a', 'trick', 'while', 'riding', 'a', 'skateboard', '.', <end>]--[0, 3, 98, 754, 3, 396, 207, 139, 3, 753, 18, 1]\n",
    "    \n",
    "    \n",
    "单词-数字对照表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<start>': 0,\n",
       " '<end>': 1,\n",
       " '<unk>': 2,\n",
       " 'a': 3,\n",
       " 'very': 4,\n",
       " 'clean': 5,\n",
       " 'and': 6,\n",
       " 'well': 7,\n",
       " 'decorated': 8,\n",
       " 'empty': 9}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(data_loader.dataset.vocab.word2idx.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以从vocabulary.py知道, word2idx字典是通过遍历训练集数据得到的.如果一个单词的出现的次数大于于`vocab_threshold`, 然后将单词添加一个key给字典,在赋值一个相应不重复的整数. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.76s)\n",
      "creating index...\n",
      "index created!\n",
      "[0/414113] Tokenizing captions...\n",
      "[100000/414113] Tokenizing captions...\n",
      "[200000/414113] Tokenizing captions...\n",
      "[300000/414113] Tokenizing captions...\n",
      "[400000/414113] Tokenizing captions...\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1198/414113 [00:00<01:10, 5875.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.77s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414113/414113 [01:08<00:00, 6045.31it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_threshold = 4\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in vocabulary: 9955\n"
     ]
    }
   ],
   "source": [
    "# Print the total number of keys in the word2idx dictionary.\n",
    "print('Total number of tokens in vocabulary:', len(data_loader.dataset.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也有一些特殊的key比如开始 (`\"<start>\"`) 结束(`\"<end>\"`)和未知值(`\"<unk>\"`). 将未知值的对应整数设置为2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special unknown word: <unk>\n",
      "All unknown words are mapped to this integer: 2\n"
     ]
    }
   ],
   "source": [
    "unk_word = data_loader.dataset.vocab.unk_word\n",
    "print('Special unknown word:', unk_word)\n",
    "\n",
    "print('All unknown words are mapped to this integer:', data_loader.dataset.vocab(unk_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以通过一些未出现在字典中的单词，测试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(data_loader.dataset.vocab('jfkafejw'))\n",
    "print(data_loader.dataset.vocab('ieowoqjf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`vocab_from_file`参数，当创建词汇表时会将创建好的词汇表存入`vocab.pkl`.所以当选择为True时，你就可以从文件读取词汇表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1180/414113 [00:00<01:14, 5549.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.82s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414113/414113 [01:08<00:00, 6080.22it/s]\n"
     ]
    }
   ],
   "source": [
    "data_loader = get_loader(transform=transform_train,mode='train',batch_size=batch_size,vocab_from_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，到了探索如何利用data_loader来获得训练数据了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: 通过使用data_loader来获得训练数据\n",
    "\n",
    "可以通过`data_loader.dataset.caption_lengths`, 可以得到标题的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: 10 --- count: 86334\n",
      "value: 11 --- count: 79948\n",
      "value:  9 --- count: 71934\n",
      "value: 12 --- count: 57637\n",
      "value: 13 --- count: 37645\n",
      "value: 14 --- count: 22335\n",
      "value:  8 --- count: 20771\n",
      "value: 15 --- count: 12841\n",
      "value: 16 --- count:  7729\n",
      "value: 17 --- count:  4842\n",
      "value: 18 --- count:  3104\n",
      "value: 19 --- count:  2014\n",
      "value:  7 --- count:  1597\n",
      "value: 20 --- count:  1451\n",
      "value: 21 --- count:   999\n",
      "value: 22 --- count:   683\n",
      "value: 23 --- count:   534\n",
      "value: 24 --- count:   383\n",
      "value: 25 --- count:   277\n",
      "value: 26 --- count:   215\n",
      "value: 27 --- count:   159\n",
      "value: 28 --- count:   115\n",
      "value: 29 --- count:    86\n",
      "value: 30 --- count:    58\n",
      "value: 31 --- count:    49\n",
      "value: 32 --- count:    44\n",
      "value: 34 --- count:    39\n",
      "value: 37 --- count:    32\n",
      "value: 33 --- count:    31\n",
      "value: 35 --- count:    31\n",
      "value: 36 --- count:    26\n",
      "value: 38 --- count:    18\n",
      "value: 39 --- count:    18\n",
      "value: 43 --- count:    16\n",
      "value: 44 --- count:    16\n",
      "value: 48 --- count:    12\n",
      "value: 45 --- count:    11\n",
      "value: 42 --- count:    10\n",
      "value: 40 --- count:     9\n",
      "value: 49 --- count:     9\n",
      "value: 46 --- count:     9\n",
      "value: 47 --- count:     7\n",
      "value: 50 --- count:     6\n",
      "value: 51 --- count:     6\n",
      "value: 41 --- count:     6\n",
      "value: 52 --- count:     5\n",
      "value: 54 --- count:     3\n",
      "value: 56 --- count:     2\n",
      "value:  6 --- count:     2\n",
      "value: 53 --- count:     2\n",
      "value: 55 --- count:     2\n",
      "value: 57 --- count:     1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#data_loader.dataset.caption_lengths  标注的长度\n",
    "counter = Counter(data_loader.dataset.caption_lengths)#返回 value(标注长度) -- count\n",
    "lengths = sorted(counter.items(), key=lambda pair: pair[1], reverse=True)\n",
    "for value, count in lengths:\n",
    "    print('value: %2d --- count: %5d' % (value, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了生成批量的训练数据，我们首先对标注长度进行采样。在采样中，抽取的特定长度的概率需要与数据集中具有该长度的标注的数量成比例。 然后，我们检索一批图像标注对的size`batch_size`，其中，所有标注都具有采样长度。 这种用于分配批次的方法与 [这篇文章 ](https://arxiv.org/pdf/1502.03044.pdf) 中的过程相匹配，并且已被证明在不降低性能的情况下具有计算上的有效性。\n",
    "运行下面的代码单元格，生成一个批次。 `CoCoDataset`类中的`get_train_indices`方法首先对标注长度进行采样，然后对与训练数据点对应的`batch_size`indices进行采样，并使用该长度的标注。 这些indices存储在`indices`下方。\n",
    "这些indices会提供给数据加载器，然后用于检索相应的数据点。该批次中的预处理图像和标注存储在`images`和`captions`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled indices: [355982, 47267, 331808, 201321, 200311, 219195, 322965, 22511, 402469, 350564]\n",
      "images.shape: torch.Size([10, 3, 224, 224])\n",
      "captions.shape: torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "#根据标注长度,随机取样\n",
    "indices = data_loader.dataset.get_train_indices()\n",
    "print('sampled indices:', indices)\n",
    "\n",
    "new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "data_loader.batch_sampler.sampler = new_sampler\n",
    "    \n",
    "# Obtain the batch.\n",
    "images, captions = next(iter(data_loader))\n",
    "    \n",
    "print('images.shape:', images.shape)\n",
    "print('captions.shape:', captions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每次运行上面的代码单元格时，都会对不同的标注长度进行采样，并返回不同批次的训练数据。多次运行代码单元格，尝试检验一下吧！\n",
    "\n",
    "在接下来的一个notebook（**2_Training.ipynb**）中训练你的模型。我们会将用于生成训练批次的代码提供给你。\n",
    "\n",
    "\n",
    "<a id='step3'></a>\n",
    "## Step 3: 使用CNN编码器进行实验\n",
    "\n",
    "运行下面的代码单元格，从**model.py**中导入`EncoderCNN`和`DecoderRNN`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Watch for any changes in model.py, and re-load it automatically.\n",
    "% load_ext autoreload\n",
    "% autoreload 2\n",
    "\n",
    "# Import EncoderCNN and DecoderRNN. \n",
    "from model import EncoderCNN, DecoderRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下一个代码单元格中，我们定义了一个device，你将使用它将PyTorch张量移动到GPU（如果CUDA可用的话）。 在进行下一步之前，运行此代码单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下面的代码单元格，在`encoder`中实例化CNN编码器。\n",
    "\n",
    "然后，该notebook的 **Step 2**中批次的预处理图像会通过编码器，且其输出会存储在`features`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(features): <class 'torch.Tensor'>\n",
      "features.shape: torch.Size([10, 256])\n"
     ]
    }
   ],
   "source": [
    "#图片嵌入的长度\n",
    "embed_size = 256\n",
    "encoder = EncoderCNN(embed_size)#获取编码器对象\n",
    "encoder.to(device)  \n",
    "images = images.to(device)\n",
    "features = encoder(images)#获取解码器对象\n",
    "print('type(features):', type(features))\n",
    "print('features.shape:', features.shape)\n",
    "assert type(features)==torch.Tensor, \"Encoder output needs to be a PyTorch Tensor.\" \n",
    "assert (features.shape[0]==batch_size) & (features.shape[1]==embed_size), \"The shape of the encoder output is incorrect.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编码器使用预先训练的ResNet-50架构（删除了最终的完全连接层）从一批预处理图像中提取特征。然后将输出展平为矢量，然后通过 `Linear`层，将特征向量转换为与单词向量同样大小的向量。\n",
    "\n",
    "![Encoder](images/encoder.png)\n",
    "\n",
    "为了试验其他架构，也可以修改 **model.py**中的编码器。 [ 使用一个不同的预训练模型架构 ](http://pytorch.org/docs/master/torchvision/models.html)。然后[ 添加批次归一化 ](http://pytorch.org/docs/master/nn.html#normalization-layers)。\n",
    "\n",
    "`EncoderCNN`类必须将`embed_size`作为一个输入参数，这个参数也将对应于你将在 Step 4 中实现的RNN解码器输入的维度。也可以对`embed_size`的值进行调整哦。\n",
    "\n",
    "<a id='step4'></a>\n",
    "## Step 4: 实现RNN解码器\n",
    "\n",
    "在执行下一个代码单元格之前，必须在**model.py**中的`DecoderRNN` 类中编写`__init__`和 `forward`方法。\n",
    "你的解码器将会是`DecoderRNN`类的一个实例，且必须接收下列输入：\n",
    "- 包含嵌入图像特征的PyTorch张量`features`（在 Step 3 中输出，当 Step 2 中的最后一批图像通过编码器时）\n",
    "- 与 Step 2中最后一批标注（`captions`）相对应的PyTorch张量。\n",
    "\n",
    "请注意，编写数据加载器的方式应该会简化你的代码。特别是，每个训练批次都包含预处理的标注，其中所有标注都具有相同的长度（`captions.shape[1]`），因此**你无需担心填充问题**。\n",
    "> 我们实现 [本文](https://arxiv.org/pdf/1411.4555.pdf)中描述的解码器，也可以实现自行选择的任何一种架构，只要至少使用一个RNN层，且隐藏维度为`hidden_size`。\n",
    "\n",
    "虽然你将使用当前存储在notebook中的最后一个批次来测试该解码器，但你的解码器应编写为接收嵌入图像特征和预处理标注的任意批次作为输入，其中所有标注具有相同的长度。\n",
    "\n",
    "![Decoder](images/decoder.png)\n",
    "\n",
    " 在下面的代码单元格中，`outputs`应该是一个大小为`[batch_size, captions.shape[1], vocab_size]`的PyTorch张量。这样设计输出的目的是`outputs[i,j,k]`包含模型的预测分数，而该分数表示批次中第 `i`个标注中的第`j`个token是词汇表中第`k`个token的可能性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(outputs): <class 'torch.Tensor'>\n",
      "outputs.shape: torch.Size([10, 10, 9955])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 512\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "decoder.to(device)\n",
    "captions = captions.to(device)\n",
    "outputs = decoder(features, captions)\n",
    "\n",
    "print('type(outputs):', type(outputs))\n",
    "print('outputs.shape:', outputs.shape)\n",
    "assert type(outputs)==torch.Tensor, \"Decoder output needs to be a PyTorch Tensor.\"\n",
    "assert (outputs.shape[0]==batch_size) & (outputs.shape[1]==captions.shape[1]) & (outputs.shape[2]==vocab_size), \"The shape of the decoder output is incorrect.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
